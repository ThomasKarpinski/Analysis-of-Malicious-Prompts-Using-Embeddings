{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a250576d-2678-45e5-bbfa-fbb6d676e960",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4817e2c1-0402-4a5e-a9f6-509f03dedaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "import sklearn\n",
    "\n",
    "#login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31503df8-4593-47a9-ab09-43543e09d01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Pandas version:\", pd.__version__)\n",
    "print(\"Numpy version:\", np.__version__)\n",
    "print(\"scikit learn version:\", sklearn.__version__)\n",
    "\n",
    "\n",
    "df = pd.read_parquet(\"hf://datasets/NASK-PIB/PL-Guard/test/data.parquet\")\n",
    "df_adversarial = pd.read_parquet(\"hf://datasets/NASK-PIB/PL-Guard/test_adversarial/data.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aae4e11-8e1d-4ac2-bc1f-02d96877727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9512792-1821-41d6-a4c1-fe7d4e8c9181",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adversarial.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76e7ad3-fd47-4e6b-9fcd-2a8b35f33034",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2).style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab8dd0b-d07e-4759-a810-c3b77cd4659d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf6ef17-12ec-4c2e-865a-ff2968e7c156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adversarial.head(2).style.set_properties(**{\n",
    "    'text-align': 'left',\n",
    "    'white-space': 'pre-wrap',\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088350fa-3260-441b-bb91-6ff10f2fc4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \" \".join(df.iloc[:, 0].dropna().astype(str).tolist())\n",
    "\n",
    "polish_stopwords = {\n",
    "    \"i\", \"w\", \"z\", \"na\", \"do\", \"że\", \"o\", \"a\", \"to\", \"się\", \n",
    "    \"jak\", \"tak\", \"jest\", \"po\", \"za\", \"ale\", \"od\", \"lub\", \"nie\", \"dla\", \"czy\", \"które\", \"takich\", \"innych\", \"jeśli\", \"takie\", \"ponieważ\", \"także\"\n",
    "}\n",
    "\n",
    "wordcloud = WordCloud(\n",
    "    width=1600, height=800,\n",
    "    background_color='white',\n",
    "    stopwords=polish_stopwords,\n",
    "    min_word_length=5\n",
    ").generate(text)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.savefig(\"Plots/wordcloud.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7f2f74-fd53-4dfb-ab5a-740ebf059774",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['text'].apply(lambda x: len(str(x).split())).describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5cc7b2-855a-4702-931a-39773854bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "lengths = df['text'].str.split().map(len)\n",
    "plt.hist(lengths, bins=50, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of prompt lengths (number of words)')\n",
    "plt.xlabel('Length')\n",
    "plt.ylabel('Number of examples')\n",
    "plt.savefig(\"Plots/WordDistribution.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b6a85e-9992-4f50-8e6c-56089ae77def",
   "metadata": {},
   "source": [
    "# Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5665bd9-35d2-491c-9691-2184066a6f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_data = df['category'].str.split('\\n', expand=True)\n",
    "split_data_adversarial = df_adversarial['category'].str.split('\\n', expand=True)\n",
    "\n",
    "\n",
    "df['category_code'] = split_data[1]\n",
    "df_adversarial['category_code'] = split_data_adversarial[1]\n",
    "\n",
    "def custom_encoder(val):\n",
    "    if val is None:\n",
    "        return 0\n",
    "        \n",
    "    val = str(val).strip()\n",
    "    \n",
    "    if val.lower() in ['safe', 'nan', 'none', '']:\n",
    "        return 0\n",
    "    \n",
    "    elif val.startswith('S'):\n",
    "        try:\n",
    "            return int(val[1:])\n",
    "        except ValueError:\n",
    "            return -1\n",
    "            \n",
    "    return -1\n",
    "\n",
    "df['target'] = df['category_code'].apply(custom_encoder)\n",
    "df_adversarial['target'] = df_adversarial['category_code'].apply(custom_encoder)\n",
    "\n",
    "print(\"Unique mappings:\")\n",
    "print(df[['category_code', 'target']].drop_duplicates().sort_values('target'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38485829-02c2-406c-9951-5507c76871df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['target'].apply(lambda x: 0 if x == 0 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a70cad-dd19-498b-a9cb-a059004f3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdeca2c-09a0-4b47-bb45-0119cd290a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_adversarial.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a690712-329f-428a-9c25-963d4b2f58de",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa6b6a9-a5d3-4a14-9a0f-e07f83c74a9e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Text Representation: Using Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942f1a18-4827-4459-a891-bbcbb73c977c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Vector representation using BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0cb802-652e-4590-80a7-32b115241ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "def get_embeddings_from_df(text_list, batch_size=32):\n",
    "    all_embeddings = []\n",
    "    \n",
    "    # I process in batches so as not to clog up the RAM with 900+ lines.h\n",
    "    for i in range(0, len(text_list), batch_size):\n",
    "        batch_texts = text_list[i:i+batch_size]\n",
    "        \n",
    "        # Tokenization\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, \n",
    "                           max_length=512, return_tensors=\"pt\")\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        # Mean Pooling\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        input_mask_expanded = inputs['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        batch_embeddings = sum_embeddings / sum_mask\n",
    "        \n",
    "        all_embeddings.append(batch_embeddings.numpy())\n",
    "    \n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "print(\"Generating vectors for clean prompts\")\n",
    "vec_original = get_embeddings_from_df(df['text'].tolist())\n",
    "\n",
    "#print(\"Generating vectors for adversarial prompts)\n",
    "#vec_adversarial = get_embeddings_from_df(df_adversarial['text'].tolist())\n",
    "\n",
    "print(f\"Gotowe. Wymiary: df={vec_original.shape}\")\n",
    "#print(f\"Shape for adversial: {vec_adversarial.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2f547e-7e2f-4d6b-bf99-7b2b0baa6e89",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Fine-tuning BERT and new vecors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e8e82b-15a8-4dfc-8284-82d8ce1befd0",
   "metadata": {},
   "source": [
    "### Training for multiple classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8a17b-c18e-4c27-ba3b-b40da5133bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from datasets import Dataset\n",
    "from transformers import BertTokenizer, AutoModelForSequenceClassification, AutoModel, TrainingArguments, Trainer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import evaluate\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import gc\n",
    "\n",
    "MODEL_NAME = \"bert-base-multilingual-cased\"\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 8\n",
    "GRAD_ACC_STEPS = 4\n",
    "EPOCHS = 5\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Used device: {device}\")\n",
    "\n",
    "\n",
    "df_orig = df.copy()\n",
    "df_adv = df_adversarial.copy()\n",
    "\n",
    "\n",
    "train_idx_orig, test_idx_orig = train_test_split(\n",
    "    np.arange(len(df_orig)), \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df_orig['target']\n",
    ")\n",
    "\n",
    "train_df_pure = df_orig.iloc[train_idx_orig][['text', 'target']].rename(columns={'target': 'label'})\n",
    "test_df_pure = df_orig.iloc[test_idx_orig][['text', 'target']].rename(columns={'target': 'label'})\n",
    "test_df_adv_full = df_adv[['text', 'target']].rename(columns={'target': 'label'})\n",
    "\n",
    "\n",
    "train_idx_mix, test_idx_mix = train_test_split(\n",
    "    np.arange(len(df_orig)), \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=df_orig['target']\n",
    ")\n",
    "\n",
    "train_df_mix = pd.concat([\n",
    "    df_orig.iloc[train_idx_mix][['text', 'target']].rename(columns={'target': 'label'}),\n",
    "    df_adv.iloc[train_idx_mix][['text', 'target']].rename(columns={'target': 'label'})\n",
    "])\n",
    "\n",
    "test_df_mix = pd.concat([\n",
    "    df_orig.iloc[test_idx_mix][['text', 'target']].rename(columns={'target': 'label'}).assign(type='original'),\n",
    "    df_adv.iloc[test_idx_mix][['text', 'target']].rename(columns={'target': 'label'}).assign(type='adversarial')\n",
    "])\n",
    "\n",
    "print(f\"Senario Pure: Train={len(train_df_pure)}, Test Orig={len(test_df_pure)}, Test Adv={len(test_df_adv_full)}\")\n",
    "print(f\"Scenario Mix:  Train={len(train_df_mix)}, Test={len(test_df_mix)}\")\n",
    "\n",
    "\n",
    "\n",
    "class WeightedTrainer(Trainer):\n",
    "    def __init__(self, class_weights, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = class_weights\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.get(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get(\"logits\")\n",
    "        loss_fct = nn.CrossEntropyLoss(weight=self.class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "def get_embeddings(text_list, model, tokenizer, batch_size=32):\n",
    "    model.eval()\n",
    "    all_embeddings = []\n",
    "    iterator = range(0, len(text_list), batch_size)\n",
    "    for i in tqdm(iterator, desc=\"Generating Vectors\", unit=\"batch\", leave=False):\n",
    "        batch_texts = text_list[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_texts, padding=True, truncation=True, max_length=MAX_LEN, return_tensors=\"pt\").to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "        \n",
    "        # Mean Pooling\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        input_mask_expanded = inputs['attention_mask'].unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * input_mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "        batch_embeddings = sum_embeddings / sum_mask\n",
    "        all_embeddings.append(batch_embeddings.cpu().numpy())\n",
    "    return np.vstack(all_embeddings)\n",
    "\n",
    "def run_training_pipeline(run_name, output_dir, train_df, test_df, dfs_to_embed):\n",
    "    \"\"\"\n",
    "    It trains the model, saves it, and generates vectors for the given DataFrames.\n",
    "    \"\"\"\n",
    "    print(f\"\\n{'='*40}\")\n",
    "    print(f\"starting scenario: {run_name}\")\n",
    "    print(f\"{'='*40}\")\n",
    "    \n",
    "    train_ds = Dataset.from_pandas(train_df[['text', 'label']])\n",
    "    test_ds = Dataset.from_pandas(test_df[['text', 'label']])\n",
    "    \n",
    "    # Tokenization\n",
    "    tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "    def tokenize(examples):\n",
    "        return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=MAX_LEN)\n",
    "    \n",
    "    print(f\"[{run_name}] Tokenization\")\n",
    "    train_ds = train_ds.map(tokenize, batched=True)\n",
    "    test_ds = test_ds.map(tokenize, batched=True)\n",
    "    \n",
    "    # weights\n",
    "    class_counts = train_df['label'].value_counts().sort_index().values\n",
    "    weights = 1.0 / class_counts\n",
    "    weights = weights / weights.sum() * len(class_counts)\n",
    "    class_weights_tensor = torch.tensor(weights, dtype=torch.float).to(device)\n",
    "    \n",
    "    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=15).to(device)\n",
    "    \n",
    "    acc_metric = evaluate.load(\"accuracy\")\n",
    "    f1_metric = evaluate.load(\"f1\")\n",
    "    \n",
    "    def compute_metrics(eval_pred):\n",
    "        logits, labels = eval_pred\n",
    "        predictions = np.argmax(logits, axis=-1)\n",
    "        acc = acc_metric.compute(predictions=predictions, references=labels)\n",
    "        f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"macro\")\n",
    "        return {**acc, **f1}\n",
    "    \n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=BATCH_SIZE,\n",
    "        gradient_accumulation_steps=GRAD_ACC_STEPS,\n",
    "        fp16=True,\n",
    "        learning_rate=2e-5,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        save_strategy=\"epoch\",\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model=\"f1\",\n",
    "        save_total_limit=1,\n",
    "        report_to=\"none\"\n",
    "    )\n",
    "    \n",
    "    trainer = WeightedTrainer(\n",
    "        class_weights=class_weights_tensor,\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=test_ds,\n",
    "        compute_metrics=compute_metrics\n",
    "    )\n",
    "    \n",
    "    print(f\"[{run_name}] Training\")\n",
    "    trainer.train()\n",
    "    \n",
    "    print(f\"[{run_name}] Saving the model\")\n",
    "    trainer.save_model(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    \n",
    "    del model, trainer\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"[{run_name}] Loading the model for feature extraction\")\n",
    "    embed_model = AutoModel.from_pretrained(output_dir).to(device)\n",
    "    \n",
    "    results = {}\n",
    "    for name, df_target in dfs_to_embed.items():\n",
    "        print(f\"[{run_name}] Generating vectors for: {name}...\")\n",
    "        embeddings = get_embeddings(df_target['text'].tolist(), embed_model, tokenizer, batch_size=BATCH_SIZE*2)\n",
    "        df_copy = df_target.copy()\n",
    "        df_copy['embedding'] = list(embeddings)\n",
    "        \n",
    "        # Zapis do pliku\n",
    "        save_path = f\"{name}_with_embeddings.pkl\"\n",
    "        df_copy.to_pickle(save_path)\n",
    "        print(f\"Saved to: {save_path}\")\n",
    "        results[name] = df_copy\n",
    "        \n",
    "    del embed_model\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return results\n",
    "\n",
    "\n",
    "# SCENARIO 1: ‘NAIVE’ MODEL (only on originals)\n",
    "# I generate vectors for:\n",
    "# 1. The original test (to check accuracy purely)\n",
    "# 2. Adversarial Full (to check how the model does NOT perform)\n",
    "output_pure = run_training_pipeline(\n",
    "    run_name=\"PURE_MODEL\",\n",
    "    output_dir=\"./bert_pure_finetuned\",\n",
    "    train_df=train_df_pure,\n",
    "    test_df=test_df_pure,\n",
    "    dfs_to_embed={\n",
    "        \"test_pure_orig\": test_df_pure,\n",
    "        \"test_pure_adv\": test_df_adv_full\n",
    "    }\n",
    ")\n",
    "\n",
    "# SCENARIO 2: MODEL \"ROBUST\" (Mix)\n",
    "output_mix = run_training_pipeline(\n",
    "    run_name=\"ROBUST_MODEL\",\n",
    "    output_dir=\"./bert_robust_finetuned\",\n",
    "    train_df=train_df_mix,\n",
    "    test_df=test_df_mix,\n",
    "    dfs_to_embed={\n",
    "        \"test_df_mix\": test_df_mix,\n",
    "        # \"train_df_mix\": train_df_mix \n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "test_df = output_mix[\"test_df_mix\"]\n",
    "\n",
    "print(\"PROCESS SUCCESSFULLY COMPLETED\")\n",
    "print(\"Available files with results (you can load them with pd.read_pickle):\")\n",
    "print(\"1. test_pure_orig_with_embeddings.pkl -> Model Pure on Orig data\")\n",
    "print(\"2. test_pure_adv_with_embeddings.pkl  -> Model Pure on Adv data\")\n",
    "print(\"3. test_df_mix_with_embeddings.pkl    -> Model Mix on Mix data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9532e6fe-47cd-4dc8-b9f8-3eceba435c4c",
   "metadata": {},
   "source": [
    "## Vector representation using FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afbb376e-2f37-4672-b466-8f622b3a4243",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "path_to_model = \"cc.pl.300.bin\"\n",
    "\n",
    "print(\"Model Loading...\")\n",
    "model = fasttext.load_model(path_to_model)\n",
    "print(\"Model is ready\")\n",
    "\n",
    "def get_vector_efficient(text):\n",
    "    clean_text = text.replace(\"\\n\", \" \")\n",
    "    # tokenization\n",
    "    return model.get_sentence_vector(clean_text)\n",
    "\n",
    "\n",
    "print(\"Vectors generating dla df...\")\n",
    "vectors_orig = [get_vector_efficient(t) for t in df['text']]\n",
    "# We convert to numpy (float32 for RAM savings)\n",
    "vec_ft_original = np.array(vectors_orig, dtype=np.float32)\n",
    "\n",
    "print(\"Vectors generating for df_adversarial...\")\n",
    "vectors_adv = [get_vector_efficient(t) for t in df_adversarial['text']]\n",
    "vec_ft_adversarial = np.array(vectors_adv, dtype=np.float32)\n",
    "\n",
    "print(f\"Finished, Shape: {vec_ft_original.shape}\")\n",
    "\n",
    "del model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835d71a5-222a-4359-b4bd-f9f9c53eb8f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dimensionality Reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7ba174-fc47-450b-8b67-6976655ae6da",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2ee977-6fcb-44eb-97e3-c5bc9ed21bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbdb43a-347c-493f-8f1a-3a02a5092a36",
   "metadata": {},
   "source": [
    "### PCA visualizations for BERT vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828da4cc-b495-4852-96f9-004b9efe85ff",
   "metadata": {},
   "source": [
    "#### 2D (two principal components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a420446-0819-4ed3-909b-b8beca142121",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 2\n",
    "\n",
    "normalizer = preprocessing.Normalizer(norm='l2')\n",
    "\n",
    "scaled_vectors_b = normalizer.fit_transform(vec_original)\n",
    "\n",
    "pca = PCA(n_components=n_components)\n",
    "pca.fit(scaled_vectors_b)\n",
    "\n",
    "pca_data = pca.transform(scaled_vectors_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7c48b3-d5b1-4d31-930b-91e3bfe79c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scree_pca(pca, method: str = \"BERT\"):\n",
    "    \n",
    "    per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "    \n",
    "    n_components = len(per_var)\n",
    "    \n",
    "    labels = ['PC' + str(x) for x in range(1, n_components + 1)]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(x=range(1, n_components + 1), height=per_var, tick_label=labels, color='skyblue', edgecolor='black')\n",
    "    \n",
    "    for i, v in enumerate(per_var):\n",
    "        plt.text(i + 1, v + 0.5, str(v) + '%', ha='center', fontweight='bold')\n",
    "\n",
    "    plt.ylabel('Percentage of Explained Variance')\n",
    "    plt.xlabel('Principal Component')\n",
    "    plt.title(f'Scree Plot for {n_components} Principal Components')\n",
    "    \n",
    "    plt.savefig(f'Plots/PcaPlots/ScreePlot_{method}_{n_components}D.png', bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bff9d4a-2ea1-4a06-a518-aecbd82a8c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scree_pca(pca, 'RawBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c2fb24-130f-46b4-9d36-01b568a94864",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = pca.explained_variance_ratio_\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "cumulative_variance = np.sum(explained_variance_ratio)\n",
    "\n",
    "print(\"\\nVariance Explained\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"PC {i+1}: {ratio:.4f} ({ratio*100:.2f}% of variance)\")\n",
    "\n",
    "print(\"...\")\n",
    "print(f\"Total variance explained by {n_components} components: {cumulative_variance:.4f} ({cumulative_variance*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f41afa-efa9-4da3-8c60-8cc5a515c332",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca_data, columns=['PC1', 'PC2'])\n",
    "\n",
    "# adding information from the original df (target i tekst)\n",
    "pca_df['target'] = df['target'].reset_index(drop=True)\n",
    "pca_df['text'] = df['text'].reset_index(drop=True)\n",
    "pca_df['category_code'] = df['category_code'].reset_index(drop=True)\n",
    "\n",
    "# for readability\n",
    "pca_df['label'] = pca_df['target'].map({0: 'Safe', 1: 'Malicious'})\n",
    "\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a208751-5a8f-4917-ba45-8627449898ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_var = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='label',\n",
    "    hover_data=['text'],\n",
    "    title='PCA analysis',\n",
    "    color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "    opacity=0.7,\n",
    "    labels={'PC1': f'PC1 ({per_var[0]:.1f}%)', 'PC2': f'PC2 ({per_var[1]:.1f}%)'}\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(width=1200,\n",
    "    height=800,\n",
    "    autosize=False,\n",
    "    hoverlabel=dict(bgcolor=\"white\", font_size=12))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896622e5-4b7a-4ab0-b7ea-125557d2079b",
   "metadata": {},
   "source": [
    "#### 3D (3 principal components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4c2f45-8c5c-40bb-87a5-be59177ba1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA for 3 componets\n",
    "pca_3d = PCA(n_components=3)\n",
    "pca_3d.fit(scaled_vectors_b) # We use the same normalized vectors as before.\n",
    "pca_data_3d = pca_3d.transform(scaled_vectors_b)\n",
    "\n",
    "print(f\"Wariancja wyjaśniona: {pca_3d.explained_variance_ratio_}\")\n",
    "print(f\"Suma: {sum(pca_3d.explained_variance_ratio_)*100:.2f}%\")\n",
    "\n",
    "df_3d = pd.DataFrame(pca_data_3d, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "# 3. We add labels and text\n",
    "df_3d['target'] = df['target'].reset_index(drop=True)\n",
    "df_3d['text'] = df['text'].reset_index(drop=True)\n",
    "df_3d['label'] = df_3d['target'].map({0: 'Safe', 1: 'Malicious'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c04d52-93ae-4172-8cb7-04c1e22664d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scree_pca(pca_3d, 'RawBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ed234a-9524-4eb6-b40d-808afbc06d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    df_3d,\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    z='PC3',\n",
    "    color='label',\n",
    "    color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "    hover_data=['text'],\n",
    "    title='Wizualizacja PCA 3D',\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "\n",
    "fig.update_layout(width=1200,\n",
    "    height=800,\n",
    "    autosize=False,\n",
    "    scene=dict(\n",
    "    xaxis_title='PC1',\n",
    "    yaxis_title='PC2',\n",
    "    zaxis_title='PC3'\n",
    "), margin=dict(l=0, r=0, b=0, t=30))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac3656a-2f7d-4ae7-8757-c7da73608437",
   "metadata": {},
   "source": [
    "### PCA visualizations for FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e717e35-5b8f-469c-a7f0-dbc5786ddaf1",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bca9e61-9c6f-4763-9acb-88c53c2110ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_ft = 2\n",
    "\n",
    "normalizer = preprocessing.Normalizer(norm='l2')\n",
    "\n",
    "scaled_vectors_ft = normalizer.fit_transform(vec_ft_original)\n",
    "\n",
    "pca_ft = PCA(n_components=n_components)\n",
    "pca_ft.fit(scaled_vectors_ft)\n",
    "\n",
    "pca_data_ft = pca_ft.transform(scaled_vectors_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6006da-7dfe-457f-a015-af03b2cb526f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scree_pca(pca_ft, 'FastText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a87335-83c4-4737-b0e9-a3a4c41c3074",
   "metadata": {},
   "outputs": [],
   "source": [
    "explained_variance_ratio = pca_ft.explained_variance_ratio_\n",
    "print(explained_variance_ratio)\n",
    "\n",
    "cumulative_variance = np.sum(explained_variance_ratio)\n",
    "\n",
    "print(\"\\nVariance Explained\")\n",
    "for i, ratio in enumerate(explained_variance_ratio):\n",
    "    print(f\"PC {i+1}: {ratio:.4f} ({ratio*100:.2f}% of variance)\")\n",
    "\n",
    "print(\"...\")\n",
    "print(f\"Total variance explained by {n_components_ft} components: {cumulative_variance:.4f} ({cumulative_variance*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180f5a0a-6083-432e-b05a-99a3dd7c0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df = pd.DataFrame(pca_data_ft, columns=['PC1', 'PC2'])\n",
    "\n",
    "pca_df['target'] = df['target'].reset_index(drop=True)\n",
    "pca_df['text'] = df['text'].reset_index(drop=True)\n",
    "pca_df['category_code'] = df['category_code'].reset_index(drop=True)\n",
    "\n",
    "pca_df['label'] = pca_df['target'].map({0: 'Safe', 1: 'Malicious'})\n",
    "\n",
    "print(pca_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c6084a-75d6-421b-bda0-76778d12ec7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "per_var_ft = np.round(pca.explained_variance_ratio_ * 100, decimals=1)\n",
    "\n",
    "fig = px.scatter(\n",
    "    pca_df,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='label',\n",
    "    hover_data=['text'],\n",
    "    title='Interaktywna analiza PCA',\n",
    "    color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "    opacity=0.7,\n",
    "    labels={'PC1': f'PC1 ({per_var_ft[0]:.1f}%)', 'PC2': f'PC2 ({per_var_ft[1]:.1f}%)'}\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(width=1200,\n",
    "    height=800,\n",
    "    autosize=False,\n",
    "    hoverlabel=dict(bgcolor=\"white\", font_size=12))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70790b2-de0a-42eb-9e94-2cae97d96bc3",
   "metadata": {},
   "source": [
    "#### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16c60c-86f7-4f07-aa2f-90e2bfaacbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_3d_ft = PCA(n_components=3)\n",
    "pca_3d_ft.fit(scaled_vectors_ft)\n",
    "pca_data_3d_ft = pca_3d_ft.transform(scaled_vectors_ft)\n",
    "\n",
    "print(f\"Explained variance: {pca_3d_ft.explained_variance_ratio_}\")\n",
    "print(f\"Summ: {sum(pca_3d_ft.explained_variance_ratio_)*100:.2f}%\")\n",
    "\n",
    "df_3d_ft = pd.DataFrame(pca_data_3d_ft, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "df_3d_ft['target'] = df['target'].reset_index(drop=True)\n",
    "df_3d_ft['text'] = df['text'].reset_index(drop=True)\n",
    "df_3d_ft['label'] = df_3d_ft['target'].map({0: 'Safe', 1: 'Malicious'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad236f5f-c659-4295-b2f7-5ea2b345291f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scree_pca(pca_3d_ft, 'FastText')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9303307a-9fd4-4aa7-85f1-ee09d68555db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    df_3d_ft,\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    z='PC3',\n",
    "    color='label',\n",
    "    color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "    hover_data=['text'],\n",
    "    title='Visualisation PCA 3D',\n",
    "    opacity=0.7\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "\n",
    "fig.update_layout(width=1200,\n",
    "    height=800,\n",
    "    autosize=False,\n",
    "    scene=dict(\n",
    "    xaxis_title='PC1',\n",
    "    yaxis_title='PC2',\n",
    "    zaxis_title='PC3'\n",
    "), margin=dict(l=0, r=0, b=0, t=40))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa4daeb-bc1a-4212-80fb-99fb888bbdea",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b37d5f-dfe6-4b2d-a279-8a98c29cc14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90a1cc8-c711-4520-969d-573991166e64",
   "metadata": {},
   "source": [
    "### t-SNE for BERT vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e404a2-76a3-40c5-af8f-3a865437a55a",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dd9653-4207-4ce5-832d-25afff097c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_sne_vis(scaled_vectors, pp):\n",
    "    pca_50 = PCA(n_components=100)\n",
    "    pca_result_50 = pca_50.fit_transform(scaled_vectors)\n",
    "    \n",
    "    # t-SNE\n",
    "    # We run for perplexity between 30 and 50\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=pp, random_state=42)\n",
    "    tsne_results = tsne.fit_transform(pca_result_50)\n",
    "    \n",
    "    df_tsne = pd.DataFrame(tsne_results, columns=['x', 'y'])\n",
    "    df_tsne['target'] = df['target'].reset_index(drop=True)\n",
    "    df_tsne['text'] = df['text'].reset_index(drop=True)\n",
    "    df_tsne['label'] = df_tsne['target'].map({0: 'Safe', 1: 'Malicious'})\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_tsne, x='x', y='y',\n",
    "        color='label',\n",
    "        hover_data=['text'],\n",
    "        title='Wizualizacja t-SNE',\n",
    "        color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "        opacity=0.7,\n",
    "        width=1000,\n",
    "        height=800\n",
    "    )\n",
    "    fig.show()\n",
    "\n",
    "t_sne_vis(scaled_vectors_b, 35)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37f930a5-9220-488d-9fb9-4113d0522549",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_50 = PCA(n_components=50)\n",
    "pca_result_50 = pca_50.fit_transform(scaled_vectors_b)\n",
    "perplexities = [5, 30, 50, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i, perp in enumerate(perplexities):\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, random_state=42, init='pca', learning_rate='auto')\n",
    "    tsne_results = tsne.fit_transform(pca_result_50)\n",
    "    \n",
    "    ax = plt.subplot(1, 4, i+1)\n",
    "    \n",
    "    scatter = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], \n",
    "                         c=df['target'], cmap='RdYlGn_r', alpha=0.6, s=10)\n",
    "    \n",
    "    ax.set_title(f'Perplexity: {perp}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3580e919-c868-47f0-af53-87d1037bff4a",
   "metadata": {},
   "source": [
    "#### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e457c706-4a58-4aa0-8aca-ffb31d9f428e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_3d = TSNE(n_components=3, verbose=1, perplexity=45, random_state=42)\n",
    "tsne_results_3d = tsne_3d.fit_transform(pca_result_50)\n",
    "\n",
    "# 2. DataFrame\n",
    "df_tsne_3d = pd.DataFrame(tsne_results_3d, columns=['x', 'y', 'z'])\n",
    "df_tsne_3d['target'] = df['target'].reset_index(drop=True)\n",
    "df_tsne_3d['text'] = df['text'].reset_index(drop=True)\n",
    "df_tsne_3d['label'] = df_tsne_3d['target'].map({0: 'Safe', 1: 'Malicious'})\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_tsne_3d, x='x', y='y', z='z',\n",
    "    color='label',\n",
    "    hover_data=['text'],\n",
    "    title='t-SNE 3D',\n",
    "    color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "fig.update_layout(width=1000, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dd2da-22d6-4c0c-8988-4179281d86f6",
   "metadata": {},
   "source": [
    "### t-SNE for FastText vector representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45650256-dd93-40a0-ada1-1a6dc46d8f7a",
   "metadata": {},
   "source": [
    "#### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1beb53fb-4072-4e0a-a6e1-72dea8af1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sne_vis(scaled_vectors_ft, 37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b3345c-d37a-422a-84cd-20022ff61bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perplexities = [5, 30, 50, 100]\n",
    "\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i, perp in enumerate(perplexities):\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, random_state=42, init='pca', learning_rate='auto')\n",
    "    tsne_results = tsne.fit_transform(pca_result_50)\n",
    "    \n",
    "    ax = plt.subplot(1, 4, i+1)\n",
    "    \n",
    "    scatter = ax.scatter(tsne_results[:, 0], tsne_results[:, 1], \n",
    "                         c=df['target'], cmap='RdYlGn_r', alpha=0.6, s=10)\n",
    "    \n",
    "    ax.set_title(f'Perplexity: {perp}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade3e33-a937-4e4c-9887-acdcf81bdbde",
   "metadata": {},
   "source": [
    "#### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99161030-9571-48ad-94f2-458d2e71aff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_3d = TSNE(n_components=3, verbose=1, perplexity=30, random_state=42)\n",
    "tsne_results_3d = tsne_3d.fit_transform(pca_result_50)\n",
    "\n",
    "df_tsne_3d = pd.DataFrame(tsne_results_3d, columns=['x', 'y', 'z'])\n",
    "df_tsne_3d['target'] = df['target'].reset_index(drop=True)\n",
    "df_tsne_3d['text'] = df['text'].reset_index(drop=True)\n",
    "df_tsne_3d['label'] = df_tsne_3d['target'].map({0: 'Safe', 1: 'Malicious'})\n",
    "\n",
    "fig = px.scatter_3d(\n",
    "    df_tsne_3d, x='x', y='y', z='z',\n",
    "    color='label',\n",
    "    hover_data=['text'],\n",
    "    title='t-SNE 3D',\n",
    "    color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=4))\n",
    "fig.update_layout(width=1000, height=800)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce76489-0e29-4f8f-98dc-406e8e7b297e",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31c7d1-1237-4e70-956a-caf75d66fafb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2274ed-53d7-47e5-a43f-4e8aeec8c56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_umap(scaled_vectors, n_components, model_type, metadata_df):\n",
    "\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=15,\n",
    "        min_dist=0.5,\n",
    "        n_components=n_components, \n",
    "        metric='cosine',   \n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    umap_embedding = reducer.fit_transform(scaled_vectors)\n",
    "\n",
    "    cols = ['x', 'y'] if n_components == 2 else ['x', 'y', 'z']\n",
    "    df_umap = pd.DataFrame(umap_embedding, columns=cols)\n",
    "    \n",
    "    df_umap['text'] = metadata_df['text'].reset_index(drop=True)\n",
    "    df_umap['target'] = metadata_df['target'].reset_index(drop=True)\n",
    "    \n",
    "    df_umap['label'] = df_umap['target'].map({0: 'Safe', 1: 'Malicious'})\n",
    "\n",
    "    title_text = f'UMAP Visualization ({model_type}) - {n_components}D'\n",
    "    \n",
    "    common_params = dict(\n",
    "        data_frame=df_umap,\n",
    "        color='label',\n",
    "        hover_data=['text'],\n",
    "        title=title_text,\n",
    "        color_discrete_map={'Safe': 'green', 'Malicious': 'red'},\n",
    "        opacity=0.7\n",
    "    )\n",
    "\n",
    "    if n_components == 2:\n",
    "        fig = px.scatter(x='x', y='y', **common_params)\n",
    "    elif n_components == 3:\n",
    "        fig = px.scatter_3d(x='x', y='y', z='z', **common_params)\n",
    "    else:\n",
    "        print(\"Error: n_components must be 2 or 3.\")\n",
    "        return\n",
    "\n",
    "    marker_size = 6 if n_components == 2 else 4\n",
    "    \n",
    "    fig.update_traces(marker=dict(size=marker_size))\n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        legend_title_text='Label',\n",
    "        margin=dict(l=0, r=0, b=0, t=40)\n",
    "    )\n",
    "\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2faed2-c395-46eb-b58f-4e9e9fd2e5dc",
   "metadata": {},
   "source": [
    "### UMAP for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c6f700-4e28-49bf-8fee-4f412774dbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_umap(\n",
    "    scaled_vectors=scaled_vectors_b, \n",
    "    n_components=2, \n",
    "    model_type=\"RawBERT\", \n",
    "    metadata_df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d2c808-17b4-4755-9dc9-c89e531482ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_umap(\n",
    "     scaled_vectors=scaled_vectors_b, \n",
    "     n_components=3, \n",
    "     model_type=\"RawBERT\", \n",
    "     metadata_df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc21e08-1a50-4b7b-a308-e5653a5be97d",
   "metadata": {},
   "source": [
    "### UMAP for FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e66c6736-6bb8-4df2-979b-02ffac981917",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_umap(\n",
    "     scaled_vectors=scaled_vectors_ft, \n",
    "     n_components=2, \n",
    "     model_type=\"FastText\", \n",
    "     metadata_df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a41a00-2648-45c1-8d68-8383028109b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_umap(\n",
    "     scaled_vectors=scaled_vectors_ft, \n",
    "     n_components=3, \n",
    "     model_type=\"FastText\", \n",
    "     metadata_df=df\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9263fda0-383e-4c78-9b09-3c4e4333abc7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dimensionality Reduction for fine-tuned BERT for 15 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9d42aae-f0dc-4ed0-b5e7-a58df84badcc",
   "metadata": {},
   "source": [
    "## PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d46888-aad7-440b-ba52-c436d09756c3",
   "metadata": {},
   "source": [
    "### 2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76417cec-3907-496d-b4c3-19be9e7b40c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "try:\n",
    "    test_df = pd.read_pickle(\"test_df_mix_with_embeddings.pkl\")\n",
    "    print(f\"Loaded vectors for {len(test_df)} samples\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Error: didn't find 'test_df_mix_with_embeddings.pkl' \")\n",
    "\n",
    "\n",
    "vectors_fine = np.stack(test_df['embedding'].values)\n",
    "\n",
    "n_components_tuned = 2\n",
    "\n",
    "normalizer = preprocessing.Normalizer(norm='l2')\n",
    "scaled_vectors_tuned = normalizer.fit_transform(vectors_fine)\n",
    "\n",
    "pca_tuned = PCA(n_components=n_components_tuned)\n",
    "pca_tuned.fit(scaled_vectors_tuned)\n",
    "pca_data_tuned = pca_tuned.transform(scaled_vectors_tuned)\n",
    "\n",
    "# calculating variation\n",
    "per_var_tuned = np.round(pca_tuned.explained_variance_ratio_ * 100, decimals=1)\n",
    "labels_tuned = ['PC' + str(x) for x in range(1, n_components_tuned+1)]\n",
    "\n",
    "cumulative_variance_tuned = np.sum(pca_tuned.explained_variance_ratio_)\n",
    "print(\"-\" * 30)\n",
    "print(f\"Variance Explained PC1: {per_var_tuned[0]}%\")\n",
    "print(f\"Variance Explained PC2: {per_var_tuned[1]}%\")\n",
    "print(f\"Total variance explained: {cumulative_variance_tuned*100:.2f}%\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84009c74-19e7-4e99-a0a0-ce60b3a54a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scree_pca(pca_tuned, 'FineTunedBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af446af0-f1cb-4c17-971a-2251cb861f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_df_tuned = pd.DataFrame(pca_data_tuned, columns=['PC1', 'PC2'])\n",
    "\n",
    "# assigning metadata (reset_index is important so that the rows match the PCA)\n",
    "pca_df_tuned['text'] = test_df['text'].reset_index(drop=True)\n",
    "pca_df_tuned['label_id'] = test_df['label'].reset_index(drop=True)\n",
    "\n",
    "# Mapping category names\n",
    "label_map = {\n",
    "    0: \"Safe\",\n",
    "    1: \"S1\",\n",
    "    2: \"S2\",\n",
    "    3: \"S3\",\n",
    "    4: \"S4\",\n",
    "    5: \"S5\",\n",
    "    6: \"S6\",\n",
    "    7: \"S7\",\n",
    "    8: \"S8\",\n",
    "    9: \"S9\",\n",
    "    10: \"S10\",\n",
    "    11: \"S11\",\n",
    "    12: \"S12\",\n",
    "    13: \"S13\",\n",
    "    14: \"S14\"\n",
    "}\n",
    "# readable columns with names\n",
    "pca_df_tuned['category_name'] = pca_df_tuned['label_id'].apply(lambda x: label_map.get(x, f\"Class {x}\"))\n",
    "pca_df_tuned = pca_df_tuned.sort_values('label_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0e3e7c-ed32-4011-a0f7-3abcdaae8917",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(\n",
    "    pca_df_tuned,\n",
    "    x='PC1',\n",
    "    y='PC2',\n",
    "    color='category_name',\n",
    "    hover_data=['text'],\n",
    "    title=f'PCA: Fine-Tuned BERT (15 KCategories) - Total Variance: {cumulative_variance_tuned*100:.1f}%',\n",
    "    opacity=0.8,\n",
    "    color_discrete_sequence=px.colors.qualitative.Dark24,\n",
    "    labels={\n",
    "        'PC1': f'PC1 ({per_var_tuned[0]:.1f}%)',\n",
    "        'PC2': f'PC2 ({per_var_tuned[1]:.1f}%)',\n",
    "        'category_name': 'Category'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=8))\n",
    "fig.update_layout(width=1100,\n",
    "    height=800,\n",
    "    autosize=False,\n",
    "    legend_title_text='Category',\n",
    "    hoverlabel=dict(bgcolor=\"white\", font_size=12)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd19614-ca67-44d5-9a9c-e139cd7a2d8b",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820751d9-d837-4414-9f97-f6cc354e71ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_tuned_3d = 3\n",
    "pca_tuned_3d = PCA(n_components=n_components_tuned_3d)\n",
    "pca_tuned_3d.fit(scaled_vectors_tuned)\n",
    "pca_data_tuned_3d = pca_tuned_3d.transform(scaled_vectors_tuned)\n",
    "\n",
    "# calculating variation\n",
    "per_var_tuned_3d = np.round(pca_tuned_3d.explained_variance_ratio_ * 100, decimals=1)\n",
    "cumulative_variance_tuned_3d = np.sum(pca_tuned_3d.explained_variance_ratio_)\n",
    "\n",
    "print(f\"Variance Explained: PC1={per_var_tuned_3d[0]}%, PC2={per_var_tuned_3d[1]}%, PC3={per_var_tuned_3d[2]}%\")\n",
    "print(f\"Total variance explained: {cumulative_variance_tuned_3d*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d3af35-f890-45a9-ad70-805dd646b082",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scree_pca(pca_tuned_3d, 'FineTunedBERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9163739-fe62-452f-89f8-0da8a892c8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_3d_fine = pd.DataFrame(pca_data_tuned_3d, columns=['PC1', 'PC2', 'PC3'])\n",
    "\n",
    "df_3d_fine['text'] = test_df['text'].reset_index(drop=True)\n",
    "df_3d_fine['label_id'] = test_df['label'].reset_index(drop=True)\n",
    "\n",
    "label_map = {\n",
    "    0: \"Safe\",\n",
    "    1: \"S1\",\n",
    "    2: \"S2\",\n",
    "    3: \"S3\",\n",
    "    4: \"S4\",\n",
    "    5: \"S5\",\n",
    "    6: \"S6\",\n",
    "    7: \"S7\",\n",
    "    8: \"S8\",\n",
    "    9: \"S9\",\n",
    "    10: \"S10\",\n",
    "    11: \"S11\",\n",
    "    12: \"S12\",\n",
    "    13: \"S13\",\n",
    "    14: \"S14\"\n",
    "}\n",
    "df_3d_fine['category_name'] = df_3d_fine['label_id'].apply(lambda x: label_map.get(x, f\"Class {x}\"))\n",
    "\n",
    "df_3d_fine = df_3d_fine.sort_values('label_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd357d5-c110-4b4e-a58c-1fea1b64746c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter_3d(\n",
    "    df_3d_fine,\n",
    "    x='PC1', \n",
    "    y='PC2', \n",
    "    z='PC3',\n",
    "    color='category_name',\n",
    "    hover_data=['text'],\n",
    "    title=f'PCA 3D: Fine-Tuned BERT (15 Categories)',\n",
    "    opacity=0.7,\n",
    "    color_discrete_sequence=px.colors.qualitative.Dark24\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=3))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    autosize=False,\n",
    "    scene=dict(\n",
    "        xaxis_title=f'PC1 ({per_var_tuned_3d[0]}%)',\n",
    "        yaxis_title=f'PC2 ({per_var_tuned_3d[1]}%)',\n",
    "        zaxis_title=f'PC3 ({per_var_tuned_3d[2]}%)'\n",
    "    ),\n",
    "    legend_title_text='Kategoria',\n",
    "    margin=dict(l=0, r=0, b=0, t=40)\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2fb878-53a4-4676-8863-0bab245dda11",
   "metadata": {},
   "source": [
    "## t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cae023b-f25a-44a0-b46c-c33139e83b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "n_samples = scaled_vectors_tuned.shape[0]\n",
    "n_comp = min(50, n_samples) \n",
    "\n",
    "pca_50 = PCA(n_components=n_comp, random_state=42)\n",
    "pca_result_50 = pca_50.fit_transform(scaled_vectors_tuned)\n",
    "\n",
    "def t_sne_vis_fnBERT(data_pca, pp, n_components=2):\n",
    "    tsne = TSNE(n_components=n_components, verbose=1, perplexity=pp, random_state=42, init='pca', learning_rate='auto')\n",
    "    tsne_results = tsne.fit_transform(data_pca)\n",
    "    \n",
    "    cols = ['x', 'y'] if n_components == 2 else ['x', 'y', 'z']\n",
    "    df_tsne = pd.DataFrame(tsne_results, columns=cols)\n",
    "    \n",
    "    df_tsne['text'] = test_df['text'].reset_index(drop=True)\n",
    "    df_tsne['label_id'] = test_df['label'].reset_index(drop=True)\n",
    "    \n",
    "    label_map = {\n",
    "        0: \"Safe\", 1: \"S1\", 2: \"S2\", 3: \"S3\", 4: \"S4\", 5: \"S5\",\n",
    "        6: \"S6\", 7: \"S7\", 8: \"S8\", 9: \"S9\", 10: \"S10\",\n",
    "        11: \"S11\", 12: \"S12\", 13: \"S13\", 14: \"S14\"\n",
    "    }\n",
    "    df_tsne['category_name'] = df_tsne['label_id'].apply(lambda x: label_map.get(x, f\"Class {x}\"))\n",
    "    df_tsne = df_tsne.sort_values('label_id')\n",
    "\n",
    "    title_text = f't-SNE {n_components}D (Perplexity={pp}) - 15 Categories'\n",
    "\n",
    "    if n_components == 2:\n",
    "        fig = px.scatter(\n",
    "            df_tsne, x='x', y='y',\n",
    "            color='category_name',\n",
    "            hover_data=['text'],\n",
    "            title=title_text,\n",
    "            color_discrete_sequence=px.colors.qualitative.Dark24, \n",
    "            opacity=0.8,\n",
    "            labels={'category_name': 'Category'}\n",
    "        )\n",
    "    elif n_components == 3:\n",
    "        fig = px.scatter_3d(\n",
    "            df_tsne, x='x', y='y', z='z',\n",
    "            color='category_name',\n",
    "            hover_data=['text'],\n",
    "            title=title_text,\n",
    "            color_discrete_sequence=px.colors.qualitative.Dark24, \n",
    "            opacity=0.8,\n",
    "            labels={'category_name': 'Category'}\n",
    "        )\n",
    "    else:\n",
    "        print(\"Błąd: n_components musi wynosić 2 lub 3.\")\n",
    "        return\n",
    "\n",
    "    marker_size = 7 if n_components == 2 else 4\n",
    "    fig.update_traces(marker=dict(size=marker_size))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        width=1000,\n",
    "        height=800,\n",
    "        legend_title_text='Category',\n",
    "        hoverlabel=dict(bgcolor=\"white\", font_size=12)\n",
    "    )\n",
    "    \n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420a8902-0022-4dcf-8059-b4f52318b41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sne_vis_fnBERT(pca_result_50, pp=30, n_components=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2996ff48-6073-4c2b-9fd0-2a7c7069a04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating Perplexity comparison...\")\n",
    "\n",
    "n_samples = pca_result_50.shape[0]\n",
    "proposed_perplexities = [5, 30, 50, 100]\n",
    "perplexities = [p for p in proposed_perplexities if p < n_samples]\n",
    "\n",
    "if len(perplexities) < 4:\n",
    "    perplexities = [5, 15, 30, int(n_samples/2)]\n",
    "    perplexities = sorted(list(set(perplexities)))\n",
    "\n",
    "plt.figure(figsize=(20, 6))\n",
    "\n",
    "\n",
    "categories = test_df['label'].reset_index(drop=True)\n",
    "\n",
    "for i, perp in enumerate(perplexities):\n",
    "    if i >= 4: break\n",
    "\n",
    "    print(f\"Calculating t-SNE for perplexity={perp}...\")\n",
    "    \n",
    "    # runnng t-SNE on the data after PCA (from the previous step)\n",
    "    tsne = TSNE(n_components=2, perplexity=perp, random_state=42, init='pca', learning_rate='auto')\n",
    "    tsne_results = tsne.fit_transform(pca_result_50)\n",
    "    \n",
    "    ax = plt.subplot(1, len(perplexities), i+1)\n",
    "    \n",
    "    scatter = ax.scatter(\n",
    "        tsne_results[:, 0], \n",
    "        tsne_results[:, 1], \n",
    "        c=categories, \n",
    "        cmap='tab20', \n",
    "        alpha=0.7, \n",
    "        s=20\n",
    "    )\n",
    "    \n",
    "    ax.set_title(f'Perplexity: {perp}')\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(\"The impact of the Perplexity parameter on cluster structure (Test Set)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2783df-07e0-485d-a3e6-4d6ce4bc5c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "X = pca_result_50\n",
    "y = test_df['label']\n",
    "\n",
    "# vector quality test\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "clf.fit(X, y)\n",
    "preds = clf.predict(X)\n",
    "print(f\"Linear separation quality (Accuracy): {accuracy_score(y, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0376423d-c302-4f3c-8a01-335bd04e328c",
   "metadata": {},
   "source": [
    "### 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef96119e-25a4-414d-9471-794e780d3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_sne_vis_fnBERT(pca_result_50, pp=30, n_components=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d8dee4-a212-47a6-a966-983b0c485074",
   "metadata": {},
   "source": [
    "## UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed5540b-cc70-4827-a94e-d71ed8357763",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = np.stack(test_df['embedding'].values)\n",
    "\n",
    "def run_and_plot_umap(vectors, n_components=2, n_neighbors=30, min_dist=0.9, embeddings=True, figure=True):\n",
    "\n",
    "    reducer = umap.UMAP(\n",
    "        n_neighbors=n_neighbors,\n",
    "        min_dist=min_dist,\n",
    "        n_components=n_components,\n",
    "        metric='cosine',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    umap_embedding = reducer.fit_transform(vectors)\n",
    "\n",
    "    cols = ['x', 'y'] if n_components == 2 else ['x', 'y', 'z']\n",
    "    df_umap = pd.DataFrame(umap_embedding, columns=cols)\n",
    "\n",
    "    df_umap['text'] = test_df['text'].reset_index(drop=True)\n",
    "    df_umap['label_id'] = test_df['label'].reset_index(drop=True)\n",
    "\n",
    "    label_map = {\n",
    "        0: \"Safe\", 1: \"S1\", 2: \"S2\", 3: \"S3\", 4: \"S4\", 5: \"S5\",\n",
    "        6: \"S6\", 7: \"S7\", 8: \"S8\", 9: \"S9\", 10: \"S10\",\n",
    "        11: \"S11\", 12: \"S12\", 13: \"S13\", 14: \"S14\"\n",
    "    }\n",
    "    df_umap['category_name'] = df_umap['label_id'].apply(lambda x: label_map.get(x, f\"Class {x}\"))\n",
    "    df_umap = df_umap.sort_values('label_id')\n",
    "\n",
    "\n",
    "    if figure is True:\n",
    "        title_text = f'UMAP {n_components}D (n_neighbors={n_neighbors}, min_dist={min_dist})'\n",
    "        \n",
    "        if n_components == 2:\n",
    "            fig = px.scatter(\n",
    "                df_umap, \n",
    "                x='x', y='y',\n",
    "                color='category_name',\n",
    "                hover_data=['text'],\n",
    "                title=title_text,\n",
    "                opacity=0.8,\n",
    "                color_discrete_sequence=px.colors.qualitative.Dark24 \n",
    "            )\n",
    "        elif n_components == 3:\n",
    "            fig = px.scatter_3d(\n",
    "                df_umap, \n",
    "                x='x', y='y', z='z',\n",
    "                color='category_name',\n",
    "                hover_data=['text'],\n",
    "                title=title_text,\n",
    "                opacity=0.8,\n",
    "                color_discrete_sequence=px.colors.qualitative.Dark24 \n",
    "            )\n",
    "        else:\n",
    "            print(\"Error: n_components must be 2 or 3\")\n",
    "            return\n",
    "    \n",
    "        marker_size = 6 if n_components == 2 else 4\n",
    "        \n",
    "        fig.update_traces(marker=dict(size=marker_size))\n",
    "        fig.update_layout(\n",
    "            width=1000,\n",
    "            height=800,\n",
    "            legend_title_text='Category',\n",
    "            hoverlabel=dict(bgcolor=\"white\", font_size=12)\n",
    "        )\n",
    "    \n",
    "        fig.show()\n",
    "    \n",
    "    if embeddings is True:\n",
    "        return umap_embedding\n",
    "    else:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c40af1-ccc9-4aa0-8069-220a9707302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_plot_umap(vectors, n_components=2, n_neighbors=30, min_dist=0.9, embeddings=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a383de-2717-4d8f-a51f-21a5a6449037",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_and_plot_umap(vectors, n_components=3, n_neighbors=30, min_dist=0.5, embeddings=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7406ccb0-b7dc-4bd7-80d6-97b3bd5b0ff4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Clustering using fine-tuned BERT vector representation (umap)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "849d6acd-1879-4a26-aeb2-fb922bb8943b",
   "metadata": {},
   "source": [
    "### kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3e877b-f9e4-4fc7-9e53-b63d465805fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b867db-29d8-4bbd-b2b2-c03b1fe8a769",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embedding_tuned = run_and_plot_umap(vectors, n_neighbors=30, embeddings=True, figure=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4228f982-e607-4bdd-96e3-4e6fc6dae74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertias = []\n",
    "# checking the range around the expected number of 15\n",
    "k_range = range(2, 20)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans_temp = KMeans(n_clusters=k, random_state=42, n_init=20)\n",
    "    kmeans_temp.fit(umap_embedding_tuned)\n",
    "    inertias.append(kmeans_temp.inertia_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(k_range, inertias, 'bx-')\n",
    "plt.xlabel('Number of clusters (k)')\n",
    "plt.ylabel('Sum of square distances')\n",
    "plt.title('Elbow method')\n",
    "plt.axvline(x=15, color='r', linestyle='--', label='The actual number of classes (15)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Plots/Clustering/kmeans_elbow.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2734ce-81c4-4a61-bf73-0946009eb773",
   "metadata": {},
   "source": [
    "- Silhouette Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d72f6e1-9bfe-4f05-b661-678d7afa0a0c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "\n",
    "X = umap_embedding_tuned \n",
    "silhouette_scores = []\n",
    "\n",
    "range_n_clusters = range(2, 16)\n",
    "\n",
    "for n_clusters in range_n_clusters:\n",
    "    fig, ax1 = plt.subplots(1, 1)\n",
    "    fig.set_size_inches(7, 5)\n",
    "\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X)\n",
    "\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    silhouette_scores.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {n_clusters}, avg silhouette score: {silhouette_avg:.4f}\")\n",
    "\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "        \n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        \n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        y_lower = y_upper + 10\n",
    "\n",
    "    ax1.set_title(f\" Silhouette for K = {n_clusters}\")\n",
    "    ax1.set_xlabel(\"Silhouette coefficient value\")\n",
    "    ax1.set_ylabel(\"Number of clusters\")\n",
    "\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([]) \n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range_n_clusters, silhouette_scores, 'bo-', linewidth=2, markersize=8)\n",
    "plt.title('Dependence of the average Silhouette Score on the number of clusters')\n",
    "plt.xlabel('Number of clusters (K)')\n",
    "plt.ylabel('Silhouette Score')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"Plots/Clustering/kmeans_silhouette_scores.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d0b8d2-bb1f-41c5-8fb8-167a2bf62ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_2 = KMeans(n_clusters=2, random_state=42, n_init=10)\n",
    "labels_k2 = kmeans_2.fit_predict(umap_embedding_tuned)\n",
    "\n",
    "df_k2 = pd.DataFrame(umap_embedding_tuned, columns=['x', 'y'])\n",
    "df_k2['Cluster'] = labels_k2.astype(str)\n",
    "df_k2['True_Label'] = test_df['label'].reset_index(drop=True)\n",
    "label_map = {\n",
    "    0: \"Safe\", 1: \"S1 (Violence)\", 2: \"S2\", 3: \"S3\", 4: \"S4\", \n",
    "    5: \"S5\", 6: \"S6\", 7: \"S7\", 8: \"S8\", 9: \"S9\", \n",
    "    10: \"S10\", 11: \"S11\", 12: \"S12\", 13: \"S13\", 14: \"S14\"\n",
    "}\n",
    "df_k2['Category_Name'] = df_k2['True_Label'].map(label_map).fillna(\"Unknown\")\n",
    "df_k2['Text'] = test_df['text'].reset_index(drop=True)\n",
    "\n",
    "# Wykres K=2\n",
    "fig2 = px.scatter(\n",
    "    df_k2, x='x', y='y',\n",
    "    color='Cluster',\n",
    "    hover_data=['Category_Name', 'Text'],\n",
    "    title='K-Means (k=2): Attempt at binary space partitioning',\n",
    "    color_discrete_sequence=['#FF0000', '#0000FF'],\n",
    "    opacity=0.7,\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "fig2.update_traces(marker=dict(size=6))\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2223fcd9-453e-4438-a034-ac90783cfe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "kmeans_15 = KMeans(n_clusters=15, random_state=42, n_init=10)\n",
    "labels_k15 = kmeans_15.fit_predict(umap_embedding_tuned)\n",
    "\n",
    "ari = adjusted_rand_score(test_df['label'], labels_k15)\n",
    "print(f\"Adjusted Rand Index (ARI) dla k=15: {ari:.4f}\")\n",
    "\n",
    "df_k15 = df_k2.copy()\n",
    "df_k15['Cluster'] = labels_k15.astype(str)\n",
    "df_k15 = df_k15.sort_values('Cluster')\n",
    "\n",
    "fig15 = px.scatter(\n",
    "    df_k15, x='x', y='y',\n",
    "    color='Cluster',\n",
    "    hover_data=['Category_Name', 'Text'],\n",
    "    title=f'K-Means (k=15): Reproduction of 15 categories (ARI={ari:.2f})',\n",
    "    color_discrete_sequence=px.colors.qualitative.Dark24,\n",
    "    opacity=0.8,\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "fig15.update_traces(marker=dict(size=6))\n",
    "fig15.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bacb9139-d1f6-4ada-8dd4-423a38e69e8d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans_12 = KMeans(n_clusters=12, random_state=42, n_init=10)\n",
    "labels_k12 = kmeans_12.fit_predict(umap_embedding_tuned)\n",
    "\n",
    "ari_12 = adjusted_rand_score(test_df['label'], labels_k12)\n",
    "print(f\"Adjusted Rand Index (ARI) dla k=12: {ari_12:.4f}\")\n",
    "\n",
    "\n",
    "df_k12 = pd.DataFrame(umap_embedding_tuned, columns=['x', 'y'])\n",
    "df_k12['Cluster'] = labels_k12\n",
    "df_k12['True_Label_ID'] = test_df['label'].reset_index(drop=True)\n",
    "\n",
    "label_map = {\n",
    "    0: \"Safe\", 1: \"S1 (Violence)\", 2: \"S2\", 3: \"S3\", 4: \"S4\", \n",
    "    5: \"S5\", 6: \"S6\", 7: \"S7\", 8: \"S8\", 9: \"S9\", \n",
    "    10: \"S10\", 11: \"S11\", 12: \"S12\", 13: \"S13\", 14: \"S14\"\n",
    "}\n",
    "df_k12['Category_Name'] = df_k12['True_Label_ID'].map(label_map).fillna(\"Unknown\")\n",
    "df_k12['Text'] = test_df['text'].reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"CLASS MERGER REPORT\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "crosstab = pd.crosstab(df_k12['Category_Name'], df_k12['Cluster'])\n",
    "\n",
    "for cluster_id in sorted(df_k12['Cluster'].unique()):\n",
    "    cluster_composition = df_k12[df_k12['Cluster'] == cluster_id]['Category_Name'].value_counts()\n",
    "    \n",
    "    major_components = cluster_composition[cluster_composition > (cluster_composition.sum() * 0.1)]\n",
    "    \n",
    "    print(f\"\\nKlaster {cluster_id}:\")\n",
    "    if len(major_components) == 1:\n",
    "        print(f\"CLEAN: Class domination {major_components.index[0]} ({major_components.values[0]} samples)\")\n",
    "    else:\n",
    "        print(f\"MERGED:\")\n",
    "        for name, count in major_components.items():\n",
    "            print(f\"     - {name}: {count} samples\")\n",
    "\n",
    "df_k12['Cluster_Label'] = df_k12['Cluster'].astype(str)\n",
    "df_k12 = df_k12.sort_values('Cluster')\n",
    "\n",
    "fig12 = px.scatter(\n",
    "    df_k12, x='x', y='y',\n",
    "    color='Cluster_Label',\n",
    "    hover_data=['Category_Name', 'Text'],\n",
    "    title=f'K-Means (k=12): Analysis of combined classes (ARI={ari_12:.4f})',\n",
    "    color_discrete_sequence=px.colors.qualitative.Dark24,\n",
    "    opacity=0.8,\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "fig12.update_traces(marker=dict(size=6))\n",
    "fig12.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5d97ba-779a-4b82-9e2b-f70248ec2e88",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f26be30-8148-44d4-8a0a-4ded4c1e938f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "import numpy as np\n",
    "\n",
    "X = umap_embedding_tuned \n",
    "y = test_df['label']\n",
    "\n",
    "methods = ['single', 'complete', 'average', 'weighted', 'centroid', 'median', 'ward']\n",
    "\n",
    "print(f\"{'Method':<15} | {'Silhouette':<10} | {'ARI':<10}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "for m in methods:\n",
    "        linked = linkage(X, method=m)\n",
    "        \n",
    "        labels = fcluster(linked, t=15, criterion='maxclust')\n",
    "        \n",
    "        sil_score = silhouette_score(X, labels)\n",
    "        \n",
    "        ari_score = adjusted_rand_score(y, labels)\n",
    "        \n",
    "        print(f\"{m:<15} | {sil_score:.3f} | {ari_score:.3f}\")\n",
    "        \n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "        \n",
    "        dendrogram(linked, \n",
    "                   ax=ax1,\n",
    "                   orientation='top',\n",
    "                   distance_sort='descending',\n",
    "                   show_leaf_counts=True,\n",
    "                   truncate_mode='lastp', # We only show the last p clusters\n",
    "                   p=40,                  # Number of branches at the bottom of the chart\n",
    "                   show_contracted=True)  # Shows how many points there are in the ‘packed’ branches.\n",
    "        \n",
    "        ax1.set_title(f'Dendrogram ({m}) - shortened')\n",
    "        ax1.set_xlabel(\"Cluster size or sample index\")\n",
    "        ax1.set_ylabel(\"Distance\")\n",
    "\n",
    "        scatter = ax2.scatter(X[:, 0], X[:, 1], c=labels, cmap='tab20', s=20, alpha=0.7)\n",
    "        ax2.set_title(f'Method: {m}\\nSilhouette: {sil_score:.3f} | ARI: {ari_score:.3f}')\n",
    "        ax2.set_xlabel(\"UMAP Dimension 1\")\n",
    "        ax2.set_ylabel(\"UMAP Dimension 2\")\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        if m == 'ward':\n",
    "            plt.savefig('Plots/Clustering/HC_ward.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b8f0a5-b37d-444f-b46e-5a0929944cd1",
   "metadata": {},
   "source": [
    "### DBSCAN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709c5b7d-1a94-4494-b97f-3f3a8f0e6dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "min_samples_val = 30\n",
    "\n",
    "neighbors = NearestNeighbors(n_neighbors=min_samples_val)\n",
    "neighbors_fit = neighbors.fit(umap_embedding_tuned)\n",
    "distances, indices = neighbors_fit.kneighbors(umap_embedding_tuned)\n",
    "\n",
    "sorted_distances = np.sort(distances[:, min_samples_val-1], axis=0)\n",
    "\n",
    "df_knee = pd.DataFrame({\n",
    "    'Index': np.arange(len(sorted_distances)),\n",
    "    'Distance': sorted_distances\n",
    "})\n",
    "\n",
    "fig = px.line(\n",
    "    df_knee, \n",
    "    x='Index', \n",
    "    y='Distance', \n",
    "    title=f'k-NN Chart (K-Nearest Neighbours Method) for k={min_samples_val}',\n",
    "    labels={'Index': 'Points sorted by distance', 'Distance': 'Epsilon value (Distance)'}\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    hovermode=\"x unified\",\n",
    "    width=1000,\n",
    "    height=600\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8348ada7-bf9f-4c99-8a6f-0582d3543a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.metrics import silhouette_score, adjusted_rand_score\n",
    "\n",
    "eps_candidates = np.arange(0.1, 2.5, 0.1)\n",
    "best_score = -1\n",
    "best_eps = -1\n",
    "best_n_clusters = -1\n",
    "\n",
    "print(f\"{'EPS':<6} | {'Clusters':<8} | {'Noise':<6} | {'Silhouette':<10} | {'ARI':<10}\")\n",
    "\n",
    "for eps in eps_candidates:\n",
    "    db = DBSCAN(eps=eps, min_samples=30)\n",
    "    labels = db.fit_predict(umap_embedding_tuned)\n",
    "    \n",
    "    n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
    "    n_noise = list(labels).count(-1)\n",
    "    \n",
    "    if 1 < n_clusters < len(umap_embedding_tuned):\n",
    "        sil = silhouette_score(umap_embedding_tuned, labels)\n",
    "        ari = adjusted_rand_score(test_df['label'], labels)\n",
    "        \n",
    "        print(f\"{eps:<6.1f} | {n_clusters:<8} | {n_noise:<6} | {sil:.4f}     | {ari:.4f}\")\n",
    "        \n",
    "        if ari > best_score:\n",
    "            best_score = ari\n",
    "            best_eps = eps\n",
    "            best_n_clusters = n_clusters\n",
    "    else:\n",
    "        print(f\"{eps:<6.1f} | {n_clusters:<8} | {n_noise:<6} | {'-':<10} | {'-':<10}\")\n",
    "\n",
    "print(f\"Best ARI score({best_score:.4f}) obtained for eps={best_eps:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2677a-d622-422e-8eb1-1410270675b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "EPS_VALUE = 1.7     # best from research above\n",
    "MIN_SAMPLES = 30\n",
    "\n",
    "dbscan = DBSCAN(eps=EPS_VALUE, min_samples=MIN_SAMPLES)\n",
    "labels_db = dbscan.fit_predict(umap_embedding_tuned)\n",
    "\n",
    "df_db = pd.DataFrame(umap_embedding_tuned, columns=['x', 'y'])\n",
    "df_db['Cluster'] = labels_db.astype(str)\n",
    "\n",
    "\n",
    "df_db['Cluster_Legend'] = df_db['Cluster'].replace('-1', 'Noise (Outliers)')\n",
    "\n",
    "df_db['Category_Name'] = test_df['label'].reset_index(drop=True).map(label_map).fillna(\"Unknown\")\n",
    "df_db['Text'] = test_df['text'].reset_index(drop=True)\n",
    "\n",
    "df_db = df_db.sort_values('Cluster_Legend')\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_db, x='x', y='y',\n",
    "    color='Cluster_Legend',\n",
    "    hover_data=['Category_Name', 'Text'],\n",
    "    title=f'DBSCAN Clustering (eps={EPS_VALUE}): 6 Clasters + Noise',\n",
    "    color_discrete_sequence=px.colors.qualitative.G10,\n",
    "    opacity=0.8,\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "\n",
    "fig.update_traces(marker=dict(size=6))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d4df806-9793-45cc-8255-cc21edc82fcf",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Outliers Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82812c4-aa50-4af7-a71b-bc3c46d08b0d",
   "metadata": {},
   "source": [
    "## Outliers using DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170382e0-cfe2-4de6-b2d6-c01da0666b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_indices = np.where(labels_db == -1)[0]\n",
    "noise_texts = test_df.iloc[noise_indices][['text', 'label']]\n",
    "\n",
    "print(f\"Number of outliers according to DBSCAN: {len(noise_texts)}\")\n",
    "print(\"\\nSample texts from DBSCAN noise:\")\n",
    "print(noise_texts.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94d97134-b72a-4bf7-84e4-dd5429686c16",
   "metadata": {},
   "source": [
    "## Isolation Forest + Raw / Fine-tuned BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bd8f4e-fa7d-40e8-b9fe-f704f8833d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "iso_forest = IsolationForest(contamination=0.05, random_state=42)\n",
    "labels_iso = iso_forest.fit_predict(umap_embedding_tuned)\n",
    "\n",
    "n_outliers_iso = list(labels_iso).count(-1)\n",
    "print(f\"Number of outliers according to Isolation Forest: {n_outliers_iso}\")\n",
    "\n",
    "df_iso = pd.DataFrame(umap_embedding_tuned, columns=['x', 'y'])\n",
    "df_iso['Anomaly'] = ['Outlier' if x == -1 else 'Normal' for x in labels_iso]\n",
    "df_iso['Text'] = test_df['text'].reset_index(drop=True)\n",
    "df_iso['Label'] = test_df['label'].reset_index(drop=True).map(label_map)\n",
    "\n",
    "fig = px.scatter(\n",
    "    df_iso, x='x', y='y',\n",
    "    color='Anomaly',\n",
    "    color_discrete_map={'Outlier': 'red', 'Normal': 'lightgrey'},\n",
    "    hover_data=['Label', 'Text'],\n",
    "    title='Isolation Forest Outlier Detection',\n",
    "    opacity=0.8,\n",
    "    width=1000,\n",
    "    height=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550afed1-e0fb-4c5d-a2e7-a9cf4a92d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_outlier_indices = set(np.where(labels_iso == -1)[0])\n",
    "\n",
    "dbscan_outlier_indices = set(np.where(labels_db == -1)[0])\n",
    "\n",
    "common_outliers = iso_outlier_indices.intersection(dbscan_outlier_indices)\n",
    "\n",
    "print(f\"Unique DBSCAN outliers: {len(dbscan_outlier_indices)}\")\n",
    "print(f\"Unique IsoForest outliers: {len(iso_outlier_indices)}\")\n",
    "print(f\"Common section (CONFIRMED ANOMALIES): {len(common_outliers)}\")\n",
    "\n",
    "if len(common_outliers) > 0:\n",
    "    print(\"\\nMOST ANOMALOUS TEXTS (Detected by both methods)\")\n",
    "    common_indices_list = list(common_outliers)\n",
    "    print(test_df.iloc[common_indices_list][['text', 'label']].head(18))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9728206a-3d28-4ead-96e8-96758c5f24b2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Impact of Adversarial Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166efffc-fea4-49da-aad6-81b733996976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "half_point = len(test_df) // 2\n",
    "\n",
    "embeddings_orig = embeddings_test[:half_point]\n",
    "embeddings_adv = embeddings_test[half_point:]\n",
    "\n",
    "\n",
    "texts_orig = test_df.iloc[:half_point]['text'].tolist()\n",
    "texts_adv = test_df.iloc[half_point:]['text'].tolist()\n",
    "labels_orig = test_df.iloc[:half_point]['label'].tolist()\n",
    "\n",
    "print(f\"divided data\")\n",
    "print(f\"amount of pairs to compare: {len(embeddings_orig)}\")\n",
    "\n",
    "\n",
    "print(\"Calculating cosine distans for every pair\")\n",
    "\n",
    "distances = []\n",
    "for i in range(len(embeddings_orig)):\n",
    "    dist = cosine(embeddings_orig[i], embeddings_adv[i])\n",
    "    distances.append(dist)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(distances, bins=50, kde=True, color='purple')\n",
    "plt.title('Adversarial Drift')\n",
    "plt.xlabel('Cosine distance (Original vs Adversarial)')\n",
    "plt.ylabel('Number of samples')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(\"Plots/Adversial_Drift.png\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "df_drift = pd.DataFrame({\n",
    "    'Original': texts_orig,\n",
    "    'Adversarial': texts_adv,\n",
    "    'Distance': distances,\n",
    "    'Label': labels_orig\n",
    "})\n",
    "\n",
    "top_movers = df_drift.sort_values('Distance', ascending=False).head(10)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TOP 10 CHANGES THAT MOST CONFUSED THE MODEL (High Drift):\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for index, row in top_movers.iterrows():\n",
    "    print(f\"\\n[Dystans: {row['Distance']:.4f}] Klasa: {row['Label']}\")\n",
    "    print(f\"ORG: {row['Original']}\")\n",
    "    print(f\"ADV: {row['Adversarial']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b96010-0bb5-4530-88c6-1e67dea13eca",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c708867-61fc-49c5-bd1f-e51912db02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "try:\n",
    "    df_pure_orig = pd.read_pickle(\"test_pure_orig_with_embeddings.pkl\") # only original\n",
    "    df_pure_adv = pd.read_pickle(\"test_pure_adv_with_embeddings.pkl\")   # only adversarial\n",
    "    df_mix = pd.read_pickle(\"test_df_mix_with_embeddings.pkl\")          # Mix (Orig + Adv)\n",
    "except FileNotFoundError:\n",
    "    print(\"Error occured during data loading\")\n",
    "    df_pure_orig, df_pure_adv, df_mix = pd.DataFrame(), pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "def get_Xy(df):\n",
    "    return np.vstack(df['embedding'].tolist()), df['label'].values\n",
    "\n",
    "\n",
    "# method A\n",
    "X_orig, y_orig = get_Xy(df_pure_orig)\n",
    "X_train_A, X_test_A, y_train_A, y_test_A = train_test_split(X_orig, y_orig, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training option A (on original prompts)...\")\n",
    "clf_A = LogisticRegression(max_iter=2000, n_jobs=-1, random_state=42)\n",
    "clf_A.fit(X_train_A, y_train_A)\n",
    "\n",
    "# Method B (mix)\n",
    "X_mix_all, y_mix_all = get_Xy(df_mix)\n",
    "X_train_B, X_test_B, y_train_B, y_test_B = train_test_split(X_mix_all, y_mix_all, test_size=0.3, random_state=42)\n",
    "\n",
    "print(\"Training option B (on mixed data)...\")\n",
    "clf_B = LogisticRegression(max_iter=2000, n_jobs=-1, random_state=42)\n",
    "clf_B.fit(X_train_B, y_train_B)\n",
    "\n",
    "# evaluation\n",
    "\n",
    "# Case 1: method A on ORIGINAL data\n",
    "preds_1 = clf_A.predict(X_test_A)\n",
    "y_true_1 = y_test_A\n",
    "label_1 = \"1. Model A (Baseline)\\nTest: Original\"\n",
    "\n",
    "# Case 2: method A on ADVERSARIAL data\n",
    "# (I take the entire adversarial set as a test, because I did not see it in method A.)\n",
    "X_adv, y_adv = get_Xy(df_pure_adv)\n",
    "preds_2 = clf_A.predict(X_adv)\n",
    "y_true_2 = y_adv\n",
    "label_2 = \"2. Model A (Atak)\\nTest: Adversarial\"\n",
    "\n",
    "# Case 3: Model B on MIX (Orig + Adv)\n",
    "# (I am testing on a separate section X_test_B, which contains both types.)\n",
    "preds_3 = clf_B.predict(X_test_B)\n",
    "y_true_3 = y_test_B\n",
    "label_3 = \"3. Model B (Robust)\\nTest: Mix (Orig+Adv)\"\n",
    "\n",
    "# results table\n",
    "\n",
    "def calculate_metrics(y_true, y_pred, scenario_name):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    return {\n",
    "        \"Scenerio\": scenario_name,\n",
    "        \"Accuracy\": acc,\n",
    "        \"Precision\": prec,\n",
    "        \"Recall\": rec,\n",
    "        \"F1-Score\": f1\n",
    "    }\n",
    "\n",
    "results_list = [\n",
    "    calculate_metrics(y_true_1, preds_1, \"Baseline (Orig)\"),\n",
    "    calculate_metrics(y_true_2, preds_2, \"Under Attack (Adv)\"),\n",
    "    calculate_metrics(y_true_3, preds_3, \"Robust Mix\")\n",
    "]\n",
    "\n",
    "df_results = pd.DataFrame(results_list)\n",
    "\n",
    "print(\"\\nComparison Table\")\n",
    "print(df_results.set_index(\"Scenerio\").round(4))\n",
    "\n",
    "# visualisation\n",
    "df_melted = df_results.melt(id_vars=\"Scenerio\", var_name=\"Metric\", value_name=\"Value\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "chart = sns.barplot(data=df_melted, x=\"Metric\", y=\"Value\", hue=\"Scenerio\", palette=[\"green\", \"red\", \"blue\"])\n",
    "plt.title(\"Comparison of model effectiveness in three scenarios\", fontsize=14)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.ylabel(\"Value (0-1)\")\n",
    "plt.legend(loc='lower right', title=\"Scenerio\")\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for container in chart.containers:\n",
    "    chart.bar_label(container, fmt='%.2f', padding=3, fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Plots/Classification/MethodsComparison.png\")\n",
    "plt.show()\n",
    "\n",
    "# confusion matrices\n",
    "fig, axes = plt.subplots(1, 3, figsize=(24, 7))\n",
    "\n",
    "scenarios = [\n",
    "    (y_true_1, preds_1, label_1),\n",
    "    (y_true_2, preds_2, label_2),\n",
    "    (y_true_3, preds_3, label_3)\n",
    "]\n",
    "\n",
    "for i, (y_true, y_pred, title) in enumerate(scenarios):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    cm_norm = cm.astype('float') / (cm.sum(axis=1)[:, np.newaxis] + 1e-9)\n",
    "    \n",
    "    sns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='Greens', ax=axes[i], cbar=False, vmin=0, vmax=1)\n",
    "    \n",
    "    axes[i].set_title(title + \" (Normalized)\", fontsize=12, fontweight='bold')\n",
    "    axes[i].set_xlabel(\"Predicted class\")\n",
    "    axes[i].set_ylabel(\"True class\")\n",
    "\n",
    "plt.suptitle(\"Comparison of effectiveness (scale 0.00 - 1.00)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"Plots/Classification/ConfusionMatrices.png\")\n",
    "plt.show()\n",
    "\n",
    "acc_base = df_results.iloc[0]['Accuracy']\n",
    "acc_attack = df_results.iloc[1]['Accuracy']\n",
    "acc_robust = df_results.iloc[2]['Accuracy']\n",
    "\n",
    "drop = (acc_base - acc_attack) * 100\n",
    "recovery = (acc_robust - acc_attack) * 100\n",
    "\n",
    "print(f\"\\nSummary:\")\n",
    "print(f\"1. Spadek jakości przez testowanie na adversarial: {drop:.2f} p.p. (Baseline vs adversarial)\")\n",
    "print(f\"2. Improvement through training on Mix: {recovery:.2f} p.p. (Attack vs Robust Mix)\")\n",
    "if acc_robust > acc_base * 1.01:\n",
    "    print(\"3. Conclusion: SUCCESS! The Robust (Mix) model achieved SIGNIFICANTLY BETTER results than the baseline model.\")\n",
    "    print(f\"   (Increase by {(acc_robust - acc_base)*100:.2f} p.p. comparing to the original).\")\n",
    "    print(\"   Adding adversarial examples worked like data augmentation, improving generalisation.\")\n",
    "elif acc_robust >= acc_base * 0.95:\n",
    "    print(\"3. Conclusion: The Robust (Mix) model has regained almost full efficiency of the base model.\")\n",
    "else:\n",
    "    print(\"3. Conclusion: The Robust (Mix) model performs better than the attacked model, but still worse than on clean data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879d87e7-9aa3-4cbb-afb6-7ecf23f92f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "print(\"\\nRandom Forest vs Logistic Regression\")\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Trening\n",
    "rf_clf.fit(X_train_B, y_train_B)\n",
    "\n",
    "# prediction\n",
    "rf_preds = rf_clf.predict(X_test_B)\n",
    "\n",
    "rf_acc = accuracy_score(y_test_B, rf_preds)\n",
    "lr_acc = df_results.iloc[2]['Accuracy']\n",
    "\n",
    "print(f\"\\nResult for Logistic Regression: {lr_acc:.4f}\")\n",
    "print(f\"Result for Random Forest:       {rf_acc:.4f}\")\n",
    "\n",
    "diff = (rf_acc - lr_acc) * 100\n",
    "if diff > 0:\n",
    "    print(f\"Conclusion: Random Forest is better by {diff:.2f} p.p.\")\n",
    "else:\n",
    "    print(f\"Conclusion: Random Forest is worse by {abs(diff):.2f} p.p.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94cf9f-c5a6-4bcb-858d-7cb6e49c293f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (DS Stable)",
   "language": "python",
   "name": "ds_stable"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
